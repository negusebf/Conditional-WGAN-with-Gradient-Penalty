{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26eb68fe",
   "metadata": {},
   "source": [
    "## <center>Conditional WGAN with Gradient Penality</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1d02e",
   "metadata": {},
   "source": [
    "Import tensorflow and enable eager execution mode. Also check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c002ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "print(\"You are using tensorflow version \"+str(tf.__version__)+\" in eager-execution mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af62349",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking for GPU availability...\")\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"--> Valid GPU of type \"+str(tf.test.gpu_device_type())+\" with name \"+tf.test.gpu_device_name()+\" found!\")\n",
    "else:\n",
    "    print(\"--> No GPU detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9071ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66181a17",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08b167",
   "metadata": {},
   "source": [
    "### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ed79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], 28, 28, 1).astype('float32')\n",
    "train_x = (train_x - 127.5) / 127.5  # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81009a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "IMG_WIDTH = 28\n",
    "IMG_HEIGHT = 28\n",
    "IMG_CHANNEL = 1\n",
    "n_classes = 10\n",
    "BATCH_SIZE = 300 # 256\n",
    "LAMBDA = 10 # For gradient penalty\n",
    "N_CRITIC = 3 # Train critic(discriminator) n times then train generator 1 time.\n",
    "\n",
    "noise_dim = 100\n",
    "EPOCHS = 50\n",
    "num_examples_to_generate = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cce675",
   "metadata": {},
   "source": [
    "#### Before you create a tensor slice for training you need to attach the one_hot labels to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25017c4",
   "metadata": {},
   "source": [
    "First concatenate the one_hot_labels with the real images and then later you will concat the one_hot_labels with the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5368d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = tf.one_hot(train_y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149218c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x))#, one_hot_labels))\n",
    "dataset = dataset.shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3620f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of training images: {train_x.shape}\")\n",
    "print(f\"Shape of training labels: {one_hot_labels.shape}\")\n",
    "print(\"Example: \")\n",
    "plt.imshow(train_x[9])\n",
    "print(train_y[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_in_channels = noise_dim #+ n_classes\n",
    "discriminator_in_channels = IMG_CHANNEL #+ n_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45568b",
   "metadata": {},
   "source": [
    "### Create the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61128cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    \n",
    "    gen_input_img = tf.keras.Input(shape=(generator_in_channels), batch_size=BATCH_SIZE)\n",
    "    dense_0 = tf.keras.layers.Dense(7*7*generator_in_channels, use_bias=False, input_shape=(generator_in_channels,))(gen_input_img)\n",
    "    bt_norm_0 = tf.keras.layers.BatchNormalization()(dense_0)\n",
    "    leaky_0 = tf.keras.layers.LeakyReLU()(bt_norm_0)\n",
    "    \n",
    "    reshaped_0 = tf.keras.layers.Reshape((7,7,generator_in_channels))(leaky_0)\n",
    "\n",
    "    assert reshaped_0.shape == (BATCH_SIZE,7,7,generator_in_channels)\n",
    "    \n",
    "    conv2dT_0 = tf.keras.layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False)(reshaped_0)\n",
    "    assert conv2dT_0.shape == (BATCH_SIZE,7,7,128)\n",
    "    bt_norm_1 = tf.keras.layers.BatchNormalization()(conv2dT_0)\n",
    "    leaky_1 = tf.keras.layers.LeakyReLU()(bt_norm_1)\n",
    "    \n",
    "    conv2dT_1 = tf.keras.layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False)(leaky_1)\n",
    "    assert conv2dT_1.shape == (BATCH_SIZE,14,14,64)\n",
    "    bt_norm_2 = tf.keras.layers.BatchNormalization()(conv2dT_1)\n",
    "    leaky_2 = tf.keras.layers.LeakyReLU()(bt_norm_2)\n",
    "    \n",
    "    output_img = tf.keras.layers.Conv2DTranspose(discriminator_in_channels, (5,5), strides=(2,2), padding='same', use_bias=False)(leaky_2)\n",
    "    assert output_img.shape == (BATCH_SIZE, IMG_WIDTH, IMG_HEIGHT, discriminator_in_channels)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=gen_input_img, outputs=output_img)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, generator_in_channels])\n",
    "test_generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(test_generated_image[0, :, :, 0], cmap='gray')\n",
    "# generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f465a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    disc_input_img = tf.keras.Input(shape=(IMG_WIDTH,IMG_HEIGHT, discriminator_in_channels), batch_size=BATCH_SIZE)\n",
    "    conv2d_0 = tf.keras.layers.Conv2D(64, (5,5), strides=(2,2), padding='same',\n",
    "                                     input_shape=[IMG_WIDTH, IMG_HEIGHT, discriminator_in_channels])(disc_input_img)\n",
    "    leaky_0 = tf.keras.layers.LeakyReLU()(conv2d_0)\n",
    "    drop_0 = tf.keras.layers.Dropout(0.3)(leaky_0)\n",
    "    \n",
    "    conv2d_1 = tf.keras.layers.Conv2D(128, (5,5), strides=(2,2), padding='same')(drop_0)\n",
    "    leaky_1 = tf.keras.layers.LeakyReLU()(conv2d_1)\n",
    "    drop_1 = tf.keras.layers.Dropout(0.3)(leaky_1)\n",
    "    \n",
    "    flatten_0 = tf.keras.layers.Flatten()(drop_1)\n",
    "    dense_0 = tf.keras.layers.Dense(1)(flatten_0)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=disc_input_img, outputs=dense_0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "test_decision = discriminator(test_generated_image)\n",
    "print(test_decision)\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fdf16",
   "metadata": {},
   "source": [
    "## Define optimizers\n",
    "\n",
    "Define loss functions and optimizers for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47869c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfacbb30",
   "metadata": {},
   "source": [
    "### Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418766d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "\n",
    "ckpt_dir = 'training_ckpts'\n",
    "ckpt_prefix = os.path.join(ckpt_dir, 'ckpt')\n",
    "ckpt = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                          discriminator_optimizer=discriminator_optimizer,\n",
    "                          generator=generator,\n",
    "                          discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([num_examples_to_generate, generator_in_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944cd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_g_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, generator_in_channels])\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as g_tape:\n",
    "        generated_image = generator(noise, training=True)\n",
    "        generated_pred = discriminator(generated_image, training=True)\n",
    "        # Calculate the loss\n",
    "        G_loss = -tf.reduce_mean(generated_pred)\n",
    "        \n",
    "    # Calculate the gradient\n",
    "    G_grad = g_tape.gradient(G_loss, generator.trainable_variables)\n",
    "    # Apply gradient\n",
    "    generator_optimizer.apply_gradients(zip(G_grad, generator.trainable_variables))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7590b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_d_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, generator_in_channels])\n",
    "    epsilon = tf.random.uniform(shape=[BATCH_SIZE, 1, 1, 1], minval=0, maxval=1)\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as d_tape:\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            generated_image = generator(noise, training=True)\n",
    "            interpolated_image = epsilon * tf.dtypes.cast(images, tf.float32) + ((1 - epsilon) * generated_image)\n",
    "            interpolated_pred = discriminator(interpolated_image, training=True)\n",
    "            \n",
    "        # Compute the gradient penality\n",
    "        grads = gp_tape.gradient(interpolated_pred, interpolated_image)\n",
    "        grad_norms = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gradient_penalty = tf.reduce_mean(tf.square(grad_norms - 1))\n",
    "        \n",
    "        generated_pred = discriminator(generated_image, training=True)\n",
    "        real_pred = discriminator(images, training=True)\n",
    "        \n",
    "        # Calculate the D_loss\n",
    "        D_loss = tf.reduce_mean(generated_pred) - tf.reduce_mean(real_pred) + LAMBDA * gradient_penalty\n",
    "    \n",
    "    # Calculate the gradient\n",
    "    D_grad = d_tape.gradient(D_loss, discriminator.trainable_variables)\n",
    "    # Apply the gradients to the optimizer\n",
    "    discriminator_optimizer.apply_gradients(zip(D_grad, discriminator.trainable_variables))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2418b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    n_critic_count = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            \n",
    "            # Train the critic/discriminator\n",
    "            train_d_step(image_batch)\n",
    "            \n",
    "            n_critic_count += 1\n",
    "            if n_critic_count >= N_CRITIC:\n",
    "                # Train the generator per N_CRITIC discriminator train steps\n",
    "                train_g_step(image_batch)\n",
    "                n_critic_count = 0\n",
    "            \n",
    "        # Produce images for GIF as you train\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, \n",
    "                                 epoch + 1,\n",
    "                                seed)\n",
    "        # Save model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            ckpt.save(file_prefix = ckpt_prefix)\n",
    "            \n",
    "        print('Time for epoch {} is {} sec'.format(epoch+1, time.time()-start))\n",
    "        \n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                            epochs,\n",
    "                            seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # You have to set training = False, because it is inference\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(predictions[i,:,:,0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.savefig('epoch_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad715fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac858a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.restore(tf.train.latest_checkpoint(ckpt_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc434f",
   "metadata": {},
   "source": [
    "### Create GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('epoch_images/image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66621346",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bca1c5",
   "metadata": {},
   "source": [
    "Use imageio to create an animated gif using the images saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f94c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
